{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is  a test program\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(\"This is  a test program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Context\n",
      "<SparkContext master=local appName=SparkContext_HIVE2>\n",
      "Hive Context\n",
      "<pyspark.sql.context.HiveContext object at 0x7f9c1c43d1d0>\n",
      "SQL Context\n",
      "<pyspark.sql.context.SQLContext object at 0x7f9c1c43bef0>\n",
      "Spark\n",
      "<pyspark.sql.session.SparkSession object at 0x7f9c02a271d0>\n",
      "[Row(count(1)=2823)]\n",
      "Row(ordernumber='10107', quantityordered='30', priceeach='95.7', orderlinenumber='2', sales='2871', orderdate='2/24/2003 0:00', status='Shipped', qtr_id='1', month_id='2', year_id='2003', productline='Motorcycles', msrp='95', productcode='S10_1678', customername='Land of Toys Inc.', phone='2125557818', addressline1='897 Long Airport Avenue', addressline2='', city='NYC', state='NY', postalcode='10022', country='USA', territory='NA', contactlastname='Yu', contactfirstname='Kwai', dealsize='Small')\n",
      "[Row(ordernumber='10107', priceeach='95.7'), Row(ordernumber='10121', priceeach='81.35')]\n",
      "+-----------+------------------+\n",
      "|  territory|             total|\n",
      "+-----------+------------------+\n",
      "|     Sweden|           1720.14|\n",
      "|    Germany|            5184.3|\n",
      "|     France|13744.239999999994|\n",
      "|         NA|  84928.1399999999|\n",
      "|      41101|           1155.06|\n",
      "|    Belgium| 727.8199999999999|\n",
      "|   530-0003|           1642.42|\n",
      "|    Finland|           7722.15|\n",
      "|      69004|3417.9200000000005|\n",
      "|       APAC|2862.9299999999994|\n",
      "|     Norway|           2556.66|\n",
      "|      Spain|24245.559999999994|\n",
      "|      79903|3718.9700000000007|\n",
      "|    Ireland|           1377.98|\n",
      "|      28023|           2641.92|\n",
      "|        USA|           3023.56|\n",
      "|         UK| 9750.919999999998|\n",
      "|Switzerland|           2713.09|\n",
      "|     Canada|2165.0000000000005|\n",
      "|      75012|           2016.97|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Create Hive Table and Write the Results\n",
      "Verify if data is written to Hive\n",
      "-----------------------------------\n",
      "Query1: select * from territory_sum\n",
      "+---------+-----+\n",
      "|territory|total|\n",
      "+---------+-----+\n",
      "|   Sweden| 1720|\n",
      "|   Sweden| 1720|\n",
      "|   Sweden| 1720|\n",
      "|  Germany| 5184|\n",
      "|  Germany| 5184|\n",
      "|  Germany| 5184|\n",
      "|   France|13744|\n",
      "|   France|13744|\n",
      "|   France|13744|\n",
      "|       NA|84928|\n",
      "|       NA|84928|\n",
      "|       NA|84928|\n",
      "|    41101| 1155|\n",
      "|    41101| 1155|\n",
      "|    41101| 1155|\n",
      "|  Belgium|  727|\n",
      "|  Belgium|  727|\n",
      "|  Belgium|  727|\n",
      "| 530-0003| 1642|\n",
      "| 530-0003| 1642|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Query2: select count(*) from territory_sum\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      72|\n",
      "+--------+\n",
      "\n",
      "Query3: select count(*) from sumterr\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      24|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import HiveContext\n",
    "import random\n",
    "conf=SparkConf().setMaster(\"local\").setAppName(\"SparkContext_HIVE2\")\n",
    "sc=SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "print(\"Spark Context\")\n",
    "print(sc)\n",
    "\n",
    "\n",
    "sql_context=SQLContext(sc)\n",
    "hive_context=HiveContext(sc)\n",
    "print(\"Hive Context\")\n",
    "print(hive_context)\n",
    "\n",
    "print(\"SQL Context\")\n",
    "print(sql_context)\n",
    "\n",
    "spark=SparkSession(sc)\n",
    "\n",
    "print(\"Spark\")\n",
    "print(spark)\n",
    "\n",
    "\n",
    "RecSales= Row('ordernumber','quantityordered','priceeach','orderlinenumber','sales','orderdate','status','qtr_id','month_id','year_id','productline','msrp','productcode','customername','phone','addressline1','addressline2','city','state','postalcode','country','territory','contactlastname','contactfirstname','dealsize')\n",
    "dataSales=sc.textFile(\"/opt/sparktest/sales_data_sample.csv\")\n",
    "header=dataSales.first()\n",
    "dataSales=dataSales.filter(lambda line: line!=header)\n",
    "recSales=dataSales.map(lambda l: l.split(\",\"))\n",
    "dataSales=recSales.map(lambda l: RecSales(l[0],l[1],l[2],l[3],l[4],l[5],l[6],l[7],l[8],l[9],l[10],l[11],l[12],l[13],l[14],l[15],l[16],l[17],l[18],l[19],l[20],l[21],l[22],l[23],l[24]))\n",
    "dfrecSales=hive_context.createDataFrame(dataSales)\n",
    "dfrecSales.registerTempTable(\"sales\")\n",
    "\n",
    "res1=hive_context.sql(\"select count(*) from sales\").collect()\n",
    "print(res1)\n",
    "res2=hive_context.sql(\"select * from sales\").head()\n",
    "print(res2)\n",
    "res3=hive_context.sql(\"select ordernumber,priceeach from sales\").head(2)\n",
    "print(res3)\n",
    "\n",
    "dfterritory=hive_context.sql(\"select territory,sum(priceeach) total from sales group by territory\")\n",
    "dfterritory.registerTempTable(\"sumterr\")\n",
    "dfterritory.show()\n",
    "\n",
    "print(\"Create Hive Table and Write the Results\")\n",
    "hive_context.sql(\"create table if not exists territory_sum (territory String, total INT)\")\n",
    "hive_context.sql(\"insert into territory_sum select * from sumterr\")\n",
    "\n",
    "print(\"Verify if data is written to Hive\")\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "print(\"Query1: select * from territory_sum\")\n",
    "hive_context.sql(\"select * from territory_sum\").show()\n",
    "\n",
    "print(\"Query2: select count(*) from territory_sum\")\n",
    "hive_context.sql(\"select count(*) from territory_sum\").show()\n",
    "\n",
    "print(\"Query3: select count(*) from sumterr\")\n",
    "hive_context.sql(\"select count(*) from sumterr\").show()\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
